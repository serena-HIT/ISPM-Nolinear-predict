{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/serena/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#The following file paths are all absolute paths. You can replace them with relative paths at runtime, and the files are located in their respective folders.\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import argparse\n",
    "from collections import OrderedDict\n",
    "from copy import copy\n",
    "from tqdm import tqdm, trange\n",
    "import scipy\n",
    "import scipy.linalg\n",
    "from scipy.integrate import odeint\n",
    "import sys\n",
    "import os\n",
    "import csv \n",
    "sys.path.append(\"/media/serena/study/Vscode_works/python_Vscode/mamba/Nonlinear_LSPN/Predict_Model_Train/\")\n",
    "sys.path.append(\"/media/serena/study/Vscode_works/python_Vscode/mamba/Nonlinear_LSPN/utility_LSPN/\")\n",
    "from LSPN_test import LSPN_Mamba\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Methods = [\"KoopmanDerivative\",\"KoopmanRBF\",\\\n",
    "            \"KNonlinear\",\"KNonlinearRNN\",\"KoopmanU\",\\\n",
    "            \"KoopmanNonlinearA\",\"KoopmanNonlinear\",\\\n",
    "            \"KNonlinearmamba\"]\n",
    "Method_names = [\"KoopmanDerivative\",\"KoopmanRBF\",\\\n",
    "            \"KDNN\",\"KRNN\",\"DKUC(ours)\",\\\n",
    "            \"DKAC(ours)\",\"DKN(ours)\",\\\n",
    "            \"KNonlinearmamba\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lorenz_dataset_original_shape(file_path, num_samples=100, num_steps=100):\n",
    "    data = np.zeros((num_samples, num_steps, 3))\n",
    "    with open(file_path, 'r', newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)  # 跳过列名行\n",
    "        for i in range(num_samples):\n",
    "            for j in range(num_steps):\n",
    "                row = next(reader)\n",
    "                data[i, j] = [float(val) for val in row]\n",
    "    return data\n",
    "\n",
    "def eval_err(suffix,method_index):\n",
    "    # method_index = 0\n",
    "    method = Methods[method_index]\n",
    "    root_path = \"/media/serena/study/Vscode_works/python_Vscode/mamba/Nonlinear_LSPN/DATA/Mamba_data_raw/\"+suffix\n",
    "    print(method)\n",
    "    if method.endswith(\"KNonlinear\"):\n",
    "        import Learn_Knonlinear as lka\n",
    "    elif method.endswith(\"KNonlinearRNN\"):\n",
    "        import Learn_Knonlinear_RNN as lka\n",
    "    elif method.endswith(\"KoopmanNonlinear\"):\n",
    "        import Learn_KoopmanNonlinear_with_KlinearEig as lka\n",
    "    elif method.endswith(\"KoopmanNonlinearA\"):\n",
    "        import Learn_KoopmanNonlinearA_with_KlinearEig as lka\n",
    "    elif method.endswith(\"KoopmanU\"):\n",
    "        import Learn_Koopman_with_KlinearEig as lka\n",
    "    elif method.endswith(\"KNonlinearmamba\"):\n",
    "        import Learn_Knonlinear_mamba_luorenz as lka   \n",
    "    for file in os.listdir(root_path):\n",
    "        if file.startswith(method+\"_\"+\"luorenz\") and file.endswith(\".pth\"):\n",
    "            model_path = file  \n",
    "    dicts = torch.load(root_path+\"/\"+model_path,map_location=torch.device('cpu'))\n",
    "    state_dict = dicts[\"model\"]\n",
    "    if method.endswith(\"KNonlinearRNN\"):\n",
    "        net = lka.Network(input_size=3,output_size=3,hidden_dim=128, n_layers=3)\n",
    "    elif method.endswith(\"KNonlinearmamba\"):\n",
    "        net = LSPN_Mamba(\n",
    "        d_model=3, \n",
    "        d_state=8, \n",
    "        d_conv=4, \n",
    "        expand=4,  \n",
    "    ).to(\"cuda\")\n",
    "    net.load_state_dict(state_dict)\n",
    "    total_params = sum(p.numel() for p in net.parameters())\n",
    "    print(f\"Total parameters: {total_params}\")\n",
    "    # net.cuda()\n",
    "    net.double()\n",
    "    Samples = 50\n",
    "    steps = 100000\n",
    "    random.seed(2022)\n",
    "    np.random.seed(2022)\n",
    "    times = 4 \n",
    "    max_loss_all = np.zeros((times,steps-1))\n",
    "    mean_loss_all = np.zeros((times,steps-1))\n",
    "    with torch.no_grad():\n",
    "        for i in trange(times, desc=\"predicting_luorenz\", unit=\"times\"):\n",
    "            X_original_shape = read_lorenz_dataset_original_shape('/media/serena/study/Vscode_works/python_Vscode/mamba/Nonlinear_LSPN/utility_LSPN/lorenz_data100000.csv',num_samples=Samples,num_steps=steps)\n",
    "            test_data = X_original_shape[-Samples:, :steps, :]\n",
    "            np.save(\"/media/serena/study/Vscode_works/python_Vscode/mamba/Nonlinear_LSPN/DATA/LSPN_predict_data/luorenz\"+suffix+\".npy\",test_data)\n",
    "            max_loss,mean_loss = lka.K_loss(test_data,net)\n",
    "            max_loss_all[i] = max_loss.reshape(-1)\n",
    "            mean_loss_all[i] = mean_loss.reshape(-1)\n",
    "    max_mean = np.mean(max_loss_all,axis=0)\n",
    "    max_std = np.std(max_loss_all,axis=0)\n",
    "    mean_mean =  np.mean(mean_loss_all,axis=0)\n",
    "    mean_std =  np.std(mean_loss_all,axis=0)\n",
    "    np.save(\"/media/serena/study/Vscode_works/python_Vscode/mamba/Nonlinear_LSPN/DATA/LSPN_luorenz_data/luorenzsteps{}\".format(steps)+suffix+\"_\"+method+\".npy\",np.array([max_mean,max_std,mean_mean,mean_std]))\n",
    "    return max_mean,max_std,mean_mean,mean_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNonlinearmamba\n",
      "Total parameters: 504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predicting_luorenz: 100%|██████████| 4/4 [00:54<00:00, 13.54s/times]\n"
     ]
    }
   ],
   "source": [
    "suffix = \"mamba_testluorenz2\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
    "\n",
    "for i in [7]:\n",
    "    #i = 2\n",
    "    eval_err(suffix,method_index=i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "font = {'size'   : 12}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "# markers = ['*','+','*','+','*','+','*']\n",
    "title = \"luorenz\"\n",
    "# compare = \"max\"\n",
    "compare = \"mean\"\n",
    "for i in [7]:\n",
    "    file_path = \"/media/serena/study/Vscode_works/python_Vscode/mamba/Nonlinear_LSPN/DATA/LSPN_luorenz_data/luorenz\"+suffix+\"_\"+Methods[i]+\".npy\"\n",
    "    data = np.load(file_path)\n",
    "    plt.plot(np.log10(data[2]),'*-',color = colors[i],label=Methods[i],linewidth=1.5)\n",
    "plt.legend()\n",
    "# plt.grid(linestyle='-.')\n",
    "plt.xlabel(\"Steps\",fontsize=12)#Pendulum-v1\n",
    "plt.ylabel(\"Log Err\",fontsize=12)\n",
    "plt.title(title,fontsize=15)\n",
    "# plt.savefig(\"D:/毕业设计/论文/pictures/sizeNN/\"+env_name+\"_TEST_\"+compare+\"_new1.png\",dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lorenz_dataset_original_shape(file_path, num_samples=100000, num_steps=100):\n",
    "    data = np.zeros((num_samples, num_steps, 3))\n",
    "    with open(file_path, 'r', newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)  # 跳过列名行\n",
    "        for i in range(num_samples):\n",
    "            for j in range(num_steps):\n",
    "                row = next(reader)\n",
    "                data[i, j] = [float(val) for val in row]\n",
    "    return data\n",
    "\n",
    "def draw_LSPN_only_eval_err(suffix,method_index,env_name = \"luorenz\"):\n",
    "    # method_index = 0\n",
    "    method = Methods[method_index]\n",
    "    root_path = \"/media/serena/study/Vscode_works/python_Vscode/mamba/Nonlinear_LSPN/DATA/Mamba_data_raw/\"+suffix\n",
    "    print(method)\n",
    "    if method.endswith(\"KNonlinear\"):\n",
    "        import Learn_Knonlinear as lka\n",
    "    elif method.endswith(\"KNonlinearRNN\"):\n",
    "        import Learn_Knonlinear_RNN as lka\n",
    "    elif method.endswith(\"KoopmanNonlinear\"):\n",
    "        import Learn_KoopmanNonlinear_with_KlinearEig as lka\n",
    "    elif method.endswith(\"KoopmanNonlinearA\"):\n",
    "        import Learn_KoopmanNonlinearA_with_KlinearEig as lka\n",
    "    elif method.endswith(\"KoopmanU\"):\n",
    "        import Learn_Koopman_with_KlinearEig as lka\n",
    "    elif method.endswith(\"KNonlinearmamba\"):\n",
    "        import Learn_Knonlinear_mamba_luolunzi as lka   \n",
    "    for file in os.listdir(root_path):\n",
    "        if file.startswith(method+\"_\"+\"luorenz\") and file.endswith(\".pth\"):\n",
    "            model_path = file  \n",
    "    dicts = torch.load(root_path+\"/\"+model_path,map_location=torch.device('cpu'))\n",
    "    state_dict = dicts[\"model\"]\n",
    "    if method.endswith(\"KNonlinearRNN\"):\n",
    "        net = lka.Network(input_size=3,output_size=3,hidden_dim=128, n_layers=3)\n",
    "    elif method.endswith(\"KNonlinearmamba\"):\n",
    "        net = LSPN_Mamba(\n",
    "        d_model=3, \n",
    "        d_state=8, \n",
    "        d_conv=4, \n",
    "        expand=4,  \n",
    "    ).to(\"cuda\")\n",
    "    net.load_state_dict(state_dict)\n",
    "    total_params = sum(p.numel() for p in net.parameters())\n",
    "    print(f\"Total parameters: {total_params}\")\n",
    "    # net.cuda()\n",
    "    net.double()\n",
    "    Samples = 50\n",
    "    steps = 51\n",
    "    random.seed(2022)\n",
    "    np.random.seed(2022)\n",
    "    times = 1\n",
    "    max_loss_all = np.zeros((Samples,steps-1))\n",
    "    mean_loss_all = np.zeros((Samples,steps-1))\n",
    "    with torch.no_grad():\n",
    "        X_original_shape = read_lorenz_dataset_original_shape('/media/serena/study/Vscode_works/python_Vscode/mamba/Nonlinear_LSPN/utility_LSPN/lorenz_data1000.csv',num_steps=steps)\n",
    "        for i in trange(Samples, desc=\"predicting_luorenz\", unit=\"times\"):\n",
    "            test_data = X_original_shape[i:i+1, :, :]\n",
    "            np.save(\"/media/serena/study/Vscode_works/python_Vscode/mamba/Nonlinear_LSPN/DATA/LSPN_predict_data/middle_data/draw_LSPN_only{}{}{}.npy\".format(i,suffix,env_name),test_data)\n",
    "            max_loss,mean_loss = lka.K_loss(test_data,net)\n",
    "            max_loss,mean_loss = np.log10(max_loss), np.log10(mean_loss)\n",
    "            max_loss_all[i] = max_loss.reshape(-1)\n",
    "            mean_loss_all[i] = mean_loss.reshape(-1)\n",
    "    print(max_loss_all.shape)\n",
    "    print(mean_loss_all.shape)\n",
    "    np.save(\"/media/serena/study/Vscode_works/python_Vscode/mamba/Nonlinear_LSPN/DATA/LSPN_predict_data/draw_LSPN_only{}\".format(Samples)+suffix+env_name+\"_\"+method+\".npy\",np.array(mean_loss_all))\n",
    "    return mean_loss_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"mamba_testluorenz2\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
    "env_name = \"luorenz\"\n",
    "for i in [7]:\n",
    "    #i = 2\n",
    "    draw_LSPN_only_eval_err(suffix,method_index=i,env_name = \"luorenz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare data for luorenz longlong 100000 steps prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lorenz_dataset_original_shape(file_path):\n",
    "    data = np.load(file_path)\n",
    "    return data\n",
    "\n",
    "\n",
    "def eval_err(suffix,method_index):\n",
    "    # method_index = 0\n",
    "    method = Methods[method_index]\n",
    "    root_path = \"/media/serena/study/Vscode_works/python_Vscode/mamba/Nonlinear_LSPN/DATA/Mamba_data_raw/\"+suffix\n",
    "    print(method)\n",
    "    if method.endswith(\"KNonlinear\"):\n",
    "        import Learn_Knonlinear as lka\n",
    "    elif method.endswith(\"KNonlinearRNN\"):\n",
    "        import Learn_Knonlinear_RNN as lka\n",
    "    elif method.endswith(\"KoopmanNonlinear\"):\n",
    "        import Learn_KoopmanNonlinear_with_KlinearEig as lka\n",
    "    elif method.endswith(\"KoopmanNonlinearA\"):\n",
    "        import Learn_KoopmanNonlinearA_with_KlinearEig as lka\n",
    "    elif method.endswith(\"KoopmanU\"):\n",
    "        import Learn_Koopman_with_KlinearEig as lka\n",
    "    elif method.endswith(\"KNonlinearmamba\"):\n",
    "        import Learn_Knonlinear_mamba_luolunzi as lka   \n",
    "    for file in os.listdir(root_path):\n",
    "        if file.startswith(method+\"_\"+\"luorenz\") and file.endswith(\".pth\"):\n",
    "            model_path = file  \n",
    "    dicts = torch.load(root_path+\"/\"+model_path,map_location=torch.device('cpu'))\n",
    "    state_dict = dicts[\"model\"]\n",
    "    if method.endswith(\"KNonlinearRNN\"):\n",
    "        net = lka.Network(input_size=3,output_size=3,hidden_dim=128, n_layers=3)\n",
    "    elif method.endswith(\"KNonlinearmamba\"):\n",
    "        net = LSPN_Mamba(\n",
    "        d_model=3, \n",
    "        d_state=8, \n",
    "        d_conv=4, \n",
    "        expand=4,  \n",
    "    ).to(\"cuda\")\n",
    "    net.load_state_dict(state_dict)\n",
    "    total_params = sum(p.numel() for p in net.parameters())\n",
    "    print(f\"Total parameters: {total_params}\")\n",
    "    # net.cuda()\n",
    "    net.double()\n",
    "    Samples = 50\n",
    "    steps = 100000\n",
    "    random.seed(2022)\n",
    "    np.random.seed(2022)\n",
    "    times = 4 \n",
    "    max_loss_all = np.zeros((times,steps-1))\n",
    "    mean_loss_all = np.zeros((times,steps-1))\n",
    "    with torch.no_grad():\n",
    "        for i in trange(times, desc=\"predicting_luorenz\", unit=\"times\"):\n",
    "            X_original_shape = read_lorenz_dataset_original_shape(\"/media/serena/study/Vscode_works/python_Vscode/mamba/Nonlinear_LSPN/utility_LSPN/luorenz_data100000.npy\")\n",
    "            test_data = X_original_shape[-Samples:, :steps, :]\n",
    "            np.save(\"/media/serena/study/Vscode_works/python_Vscode/mamba/Nonlinear_LSPN/DATA/LSPN_predict_data/luorenz\"+suffix+\".npy\",test_data)\n",
    "            max_loss,mean_loss = lka.K_loss(test_data,net)\n",
    "            max_loss_all[i] = max_loss.reshape(-1)\n",
    "            mean_loss_all[i] = mean_loss.reshape(-1)\n",
    "    max_mean = np.mean(max_loss_all,axis=0)\n",
    "    max_std = np.std(max_loss_all,axis=0)\n",
    "    mean_mean =  np.mean(mean_loss_all,axis=0)\n",
    "    mean_std =  np.std(mean_loss_all,axis=0)\n",
    "    np.save(\"/media/serena/study/Vscode_works/python_Vscode/mamba/Nonlinear_LSPN/DATA/LSPN_luorenz_data/luorenzsteps{}\".format(steps)+suffix+\"_\"+method+\".npy\",np.array([max_mean,max_std,mean_mean,mean_std]))\n",
    "    return max_mean,max_std,mean_mean,mean_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNonlinearmamba\n",
      "Total parameters: 504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predicting_luorenz: 100%|██████████| 4/4 [00:25<00:00,  6.27s/times]\n"
     ]
    }
   ],
   "source": [
    "suffix = \"mamba_testluorenz2\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
    "\n",
    "for i in [7]:\n",
    "    #i = 2\n",
    "    eval_err(suffix,method_index=i)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a4d06311c44a4bca643a5b6bd1fed619513a1bbcc6119049a755b6c84aad7bef"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
