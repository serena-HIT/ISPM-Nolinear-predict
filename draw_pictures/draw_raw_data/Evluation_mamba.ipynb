{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/serena/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#The following file paths are all absolute paths. You can replace them with relative paths at runtime, and the files are located in their respective folders.\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import argparse\n",
    "from collections import OrderedDict\n",
    "from copy import copy\n",
    "from tqdm import tqdm, trange\n",
    "import time\n",
    "import scipy\n",
    "import scipy.linalg\n",
    "from scipy.integrate import odeint\n",
    "import sys\n",
    "import os\n",
    "os.chdir(r'/media/serena/study/Vscode_works/python_Vscode/mamba/Nonlinear_LSPN/')\n",
    "import csv\n",
    "sys.path.append(\"Predict_Model_Train/\")\n",
    "sys.path.append(\"utility_LSPN/\")\n",
    "from Utility import data_collecter\n",
    "from LSPN_test import LSPN_Mamba\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Methods = [\"KoopmanDerivative\",\"KoopmanRBF\",\\\n",
    "            \"KNonlinear\",\"KNonlinearRNN\",\"KoopmanU\",\\\n",
    "            \"KoopmanNonlinearA\",\"KoopmanNonlinear\",\\\n",
    "            \"KNonlinearmamba\"]\n",
    "Method_names = [\"KoopmanDerivative\",\"KoopmanRBF\",\\\n",
    "            \"KDNN\",\"KRNN\",\"DKUC(ours)\",\\\n",
    "            \"DKAC(ours)\",\"DKN(ours)\",\\\n",
    "            \"KNonlinearmamba\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_err(suffix,env_name,method_index):\n",
    "    method = Methods[method_index]\n",
    "    root_path = \"/media/serena/study/Vscode_works/python_Vscode/mamba/Nonlinear_LSPN/DATA/Mamba_data_raw/\"+suffix\n",
    "    print(method)\n",
    "    if method.endswith(\"KNonlinear\"):\n",
    "        import Learn_Knonlinear as lka\n",
    "    elif method.endswith(\"KNonlinearRNN\"):\n",
    "        import Learn_Knonlinear_RNN as lka\n",
    "    elif method.endswith(\"KoopmanNonlinear\"):\n",
    "        import Learn_KoopmanNonlinear_with_KlinearEig as lka\n",
    "    elif method.endswith(\"KoopmanNonlinearA\"):\n",
    "        import Learn_KoopmanNonlinearA_with_KlinearEig as lka\n",
    "    elif method.endswith(\"KoopmanU\"):\n",
    "        import Learn_Koopman_with_KlinearEig as lka\n",
    "    elif method.endswith(\"KNonlinearmamba\"):\n",
    "        import Learn_Knonlinear_mamba as lka   \n",
    "    for file in os.listdir(root_path):\n",
    "        if file.startswith(method+\"_\"+env_name) and file.endswith(\".pth\"):\n",
    "            model_path = file  \n",
    "    Data_collect = data_collecter(env_name)\n",
    "    udim = Data_collect.udim\n",
    "    Nstates = Data_collect.Nstates\n",
    "    layer_width = 128\n",
    "    dicts = torch.load(root_path+\"/\"+model_path,map_location=torch.device('cpu'))\n",
    "    state_dict = dicts[\"model\"]\n",
    "    if method.endswith(\"KNonlinear\"):\n",
    "        Elayer = dicts[\"Elayer\"]\n",
    "        net = lka.Network(layers=Elayer,u_dim=udim)\n",
    "    elif method.endswith(\"KNonlinearRNN\"):\n",
    "        net = lka.Network(input_size=udim+Nstates,output_size=Nstates,hidden_dim=layer_width, n_layers=3)\n",
    "    elif method.endswith(\"KNonlinearmamba\"):\n",
    "        net = LSPN_Mamba(\n",
    "        # This module uses roughly 3 * expand * d_model^2 parameters\n",
    "        d_model=3, # Model dimension d_model\n",
    "        d_state=8,  # SSM state expansion factor\n",
    "        d_conv=4,    # Local convolution width\n",
    "        expand=4,    # Block expansion factor\n",
    "    ).to(\"cuda\")\n",
    "    elif method.endswith(\"KoopmanNonlinear\") or method.endswith(\"KoopmanNonlinearA\"):\n",
    "        layer = dicts[\"layer\"]\n",
    "        blayer = dicts[\"blayer\"]\n",
    "        NKoopman = layer[-1]+Nstates\n",
    "        net = lka.Network(layer,blayer,NKoopman,udim)\n",
    "    elif method.endswith(\"KoopmanU\"):\n",
    "        layer = dicts[\"layer\"]\n",
    "        NKoopman = layer[-1]+Nstates\n",
    "        net = lka.Network(layer,NKoopman,udim)   \n",
    "    net.load_state_dict(state_dict)\n",
    "    total_params = sum(p.numel() for p in net.parameters())\n",
    "    print(f\"Total parameters: {total_params}\")\n",
    "    # net.cuda()\n",
    "    net.double()\n",
    "    Samples = 50\n",
    "    steps = 1000\n",
    "    random.seed(2022)\n",
    "    np.random.seed(2022)\n",
    "    times = 4 \n",
    "    max_loss_all = np.zeros((times,steps))\n",
    "    mean_loss_all = np.zeros((times,steps))\n",
    "    # Test_time = np.zeros(())\n",
    "    with torch.no_grad():\n",
    "        for i in trange(times, desc=\"predicting\", unit=\"times\"):\n",
    "            test_data_path = \"/media/serena/study/Vscode_works/python_Vscode/mamba/Nonlinear_LSPN/DATA/LSPN_predict_data/middle_data/{}{}{}.npy\".format(i,suffix,env_name)\n",
    "            # if os.path.exists(test_data_path):\n",
    "            #     test_data = np.load(\"/media/serena/study/毕业设计/中期/Python/MPC_trykoopman/results/difcompare_data/{}{}.npy\".format(env_name,i))\n",
    "            # else:\n",
    "            test_data = Data_collect.collect_koopman_data(Samples,steps)\n",
    "            # np.save(\"/media/serena/study/Vscode_works/python_Vscode/mamba/Nonlinear_LSPN/DATA/LSPN_predict_data/middle_data/{}{}{}.npy\".format(i,suffix,env_name),test_data)\n",
    "            \n",
    "            max_loss,mean_loss = lka.K_loss(test_data,net,udim)\n",
    "            max_loss_all[i] = max_loss.reshape(-1)\n",
    "            mean_loss_all[i] = mean_loss.reshape(-1)\n",
    "    max_mean = np.mean(max_loss_all,axis=0)\n",
    "    max_std = np.std(max_loss_all,axis=0)\n",
    "    mean_mean =  np.mean(mean_loss_all,axis=0)\n",
    "    mean_std =  np.std(mean_loss_all,axis=0)\n",
    "    np.save(\"/media/serena/study/Vscode_works/python_Vscode/mamba/Nonlinear_LSPN/DATA/LSPN_predict_data/steps{}\".format(steps)+suffix+env_name+\"_\"+method+\".npy\",np.array([max_mean,max_std,mean_mean,mean_std]))\n",
    "    return max_mean,max_std,mean_mean,mean_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNonlinearmamba\n",
      "Total parameters: 504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predicting: 100%|██████████| 4/4 [00:15<00:00,  3.87s/times]\n"
     ]
    }
   ],
   "source": [
    "suffix = \"mamba_test6\" \n",
    "# suffix = \"mamba_test_50_5k_2w\"       #6,8,9  \n",
    "# suffix = \"mamba_dampingpendulum\"\n",
    "env_name = \"DampingPendulum\"\n",
    "# env_name = \"MountainCarContinuous-v0\"\n",
    "# env_name = \"Pendulum-v1\"\n",
    "for i in [7]:\n",
    "    #i = 2\n",
    "    eval_err(suffix,env_name,method_index=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "font = {'size'   : 12}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "# markers = ['*','+','*','+','*','+','*']\n",
    "#env_name = \"DampingPendulum\"\n",
    "#env_name = \"CartPole-v1\"\n",
    "# env_name = \"MountainCarContinuous-v0\"\n",
    "# env_name = \"Pendulum-v1\"\n",
    "# env_name = \"Franka\"\n",
    "# env_name = \"DoublePendulum\"\n",
    "title = env_name\n",
    "# compare = \"max\"\n",
    "compare = \"mean\"\n",
    "#i = 2\n",
    "#plt.plot(np.log10(data[0]),'*-',color = colors[i],label=\"Layer Depth of NNs = {}\".format(i+1),linewidth=1.5)\n",
    "for i in [7]:\n",
    "    file_path = \"/media/serena/study/Vscode_works/python_Vscode/mamba/Nonlinear_LSPN/DATA/LSPN_predict_data/steps{}\".format(steps)+suffix+env_name+\"_\"+Methods[i]+\".npy\"\n",
    "    data = np.load(file_path)\n",
    "    plt.plot(np.log10(data[2]),'*-',color = colors[i],label=Methods[i],linewidth=1.5)\n",
    "plt.legend()\n",
    "# plt.grid(linestyle='-.')\n",
    "plt.xlabel(\"Steps\",fontsize=12)\n",
    "plt.ylabel(\"Log Err\",fontsize=12)\n",
    "plt.title(title,fontsize=15)\n",
    "# plt.savefig(\"D:/毕业设计/论文/pictures/sizeNN/\"+env_name+\"_TEST_\"+compare+\"_new1.png\",dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_LSPN_only_eval_err(suffix,env_name,method_index):\n",
    "    method = Methods[method_index]\n",
    "    root_path = \"/media/serena/study/Vscode_works/python_Vscode/mamba/Nonlinear_LSPN/DATA/Mamba_data_raw/\"+suffix\n",
    "    print(method)\n",
    "    if method.endswith(\"KNonlinear\"):\n",
    "        import Learn_Knonlinear as lka\n",
    "    elif method.endswith(\"KNonlinearRNN\"):\n",
    "        import Learn_Knonlinear_RNN as lka\n",
    "    elif method.endswith(\"KoopmanNonlinear\"):\n",
    "        import Learn_KoopmanNonlinear_with_KlinearEig as lka\n",
    "    elif method.endswith(\"KoopmanNonlinearA\"):\n",
    "        import Learn_KoopmanNonlinearA_with_KlinearEig as lka\n",
    "    elif method.endswith(\"KoopmanU\"):\n",
    "        import Learn_Koopman_with_KlinearEig as lka\n",
    "    elif method.endswith(\"KNonlinearmamba\"):\n",
    "        import Learn_Knonlinear_mamba as lka   \n",
    "    for file in os.listdir(root_path):\n",
    "        if file.startswith(method+\"_\"+env_name) and file.endswith(\".pth\"):\n",
    "            model_path = file  \n",
    "    Data_collect = data_collecter(env_name)\n",
    "    udim = Data_collect.udim\n",
    "    Nstates = Data_collect.Nstates\n",
    "    layer_width = 128\n",
    "    dicts = torch.load(root_path+\"/\"+model_path,map_location=torch.device('cpu'))\n",
    "    state_dict = dicts[\"model\"]\n",
    "    if method.endswith(\"KNonlinear\"):\n",
    "        Elayer = dicts[\"Elayer\"]\n",
    "        net = lka.Network(layers=Elayer,u_dim=udim)\n",
    "    elif method.endswith(\"KNonlinearRNN\"):\n",
    "        net = lka.Network(input_size=udim+Nstates,output_size=Nstates,hidden_dim=layer_width, n_layers=3)\n",
    "    elif method.endswith(\"KNonlinearmamba\"):\n",
    "        net = LSPN_Mamba(\n",
    "        # This module uses roughly 3 * expand * d_model^2 parameters\n",
    "        d_model=3, # Model dimension d_model\n",
    "        d_state=8,  # SSM state expansion factor\n",
    "        d_conv=4,    # Local convolution width\n",
    "        expand=4,    # Block expansion factor\n",
    "    ).to(\"cuda\")\n",
    "    elif method.endswith(\"KoopmanNonlinear\") or method.endswith(\"KoopmanNonlinearA\"):\n",
    "        layer = dicts[\"layer\"]\n",
    "        blayer = dicts[\"blayer\"]\n",
    "        NKoopman = layer[-1]+Nstates\n",
    "        net = lka.Network(layer,blayer,NKoopman,udim)\n",
    "    elif method.endswith(\"KoopmanU\"):\n",
    "        layer = dicts[\"layer\"]\n",
    "        NKoopman = layer[-1]+Nstates\n",
    "        net = lka.Network(layer,NKoopman,udim)   \n",
    "    net.load_state_dict(state_dict)\n",
    "    total_params = sum(p.numel() for p in net.parameters())\n",
    "    print(f\"Total parameters: {total_params}\")\n",
    "    # net.cuda()\n",
    "    net.double()\n",
    "    Samples = 50\n",
    "    steps = 50\n",
    "    random.seed(2022)\n",
    "    np.random.seed(2022)\n",
    "    times = 1\n",
    "    max_loss_all = np.zeros((Samples,steps))\n",
    "    mean_loss_all = np.zeros((Samples,steps))\n",
    "    with torch.no_grad():\n",
    "        test_data_all = Data_collect.collect_koopman_data(Samples,steps)\n",
    "        for i in trange(Samples, desc=\"predicting\", unit=\"Samples\"):\n",
    "            test_data = test_data_all[:, i:i+1, :]\n",
    "            np.save(\"/media/serena/study/Vscode_works/python_Vscode/mamba/Nonlinear_LSPN/DATA/LSPN_predict_data/middle_data/draw_LSPN_only{}{}{}.npy\".format(i,suffix,env_name),test_data)\n",
    "            max_loss,mean_loss = lka.K_loss(test_data,net,udim)\n",
    "            max_loss,mean_loss = np.log10(max_loss), np.log10(mean_loss)\n",
    "            max_loss_all[i] = max_loss.reshape(-1)\n",
    "            mean_loss_all[i] = mean_loss.reshape(-1)\n",
    "    print(max_loss_all.shape)\n",
    "    print(mean_loss_all.shape)\n",
    "    np.save(\"/media/serena/study/Vscode_works/python_Vscode/mamba/Nonlinear_LSPN/DATA/LSPN_predict_data/draw_LSPN_only{}\".format(Samples)+suffix+env_name+\"_\"+method+\".npy\",np.array(mean_loss_all))\n",
    "    return mean_loss_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"mamba_test_50_5k_2w\"       #6,8,9  \n",
    "# suffix = \"mamba_dampingpendulum\"\n",
    "# env_name = \"DampingPendulum\"\n",
    "env_name = \"MountainCarContinuous-v0\"\n",
    "# env_name = \"Pendulum-v1\"\n",
    "for i in [7]:\n",
    "    #i = 2\n",
    "    draw_LSPN_only_eval_err(suffix,env_name,method_index=i)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a4d06311c44a4bca643a5b6bd1fed619513a1bbcc6119049a755b6c84aad7bef"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
